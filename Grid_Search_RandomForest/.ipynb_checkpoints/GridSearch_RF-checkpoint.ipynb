{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26252,
     "status": "ok",
     "timestamp": 1617697024935,
     "user": {
      "displayName": "Clivian Li",
      "photoUrl": "",
      "userId": "07011166860670723255"
     },
     "user_tz": -480
    },
    "id": "VK6Js1BPR6qc",
    "outputId": "8e93f098-b020-4741-9446-d073c2e9084b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26248,
     "status": "ok",
     "timestamp": 1617697024936,
     "user": {
      "displayName": "Clivian Li",
      "photoUrl": "",
      "userId": "07011166860670723255"
     },
     "user_tz": -480
    },
    "id": "iMw-db_dilDQ",
    "outputId": "fd068218-a472-484c-a9c7-b7b641111280"
   },
   "outputs": [],
   "source": [
    "# cd ColabNotebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27362,
     "status": "ok",
     "timestamp": 1617697026055,
     "user": {
      "displayName": "Clivian Li",
      "photoUrl": "",
      "userId": "07011166860670723255"
     },
     "user_tz": -480
    },
    "id": "5_ipiZenipDb",
    "outputId": "bf331c13-e759-4a91-9f14-597e1be5a051"
   },
   "outputs": [],
   "source": [
    "# ls\n",
    "# print(np.expm1(np.log1p(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35364,
     "status": "ok",
     "timestamp": 1617697034060,
     "user": {
      "displayName": "Clivian Li",
      "photoUrl": "",
      "userId": "07011166860670723255"
     },
     "user_tz": -480
    },
    "id": "2DkCsTLNg6zg",
    "outputId": "0a1c552b-a66e-40c2-dc6c-51be8d42943a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['material' 'product_type' 'indust_part'\n",
      " 'school_education_centers_top_20_raion' 'hospital_beds_raion'\n",
      " 'healthcare_centers_raion' 'university_top_20_raion'\n",
      " 'additional_education_raion' 'culture_objects_top_25'\n",
      " 'thermal_power_plant_raion' 'incineration_raion' 'oil_chemistry_raion'\n",
      " 'radiation_raion' 'railroad_terminal_raion' 'big_market_raion'\n",
      " 'nuclear_reactor_raion' 'detention_facility_raion' '16_29_male'\n",
      " 'build_count_block' 'build_count_frame' 'build_count_monolith'\n",
      " 'build_count_foam' 'build_count_before_1920' 'build_count_1971-1995'\n",
      " 'ID_metro' 'kindergarten_km' 'park_km' 'green_zone_km'\n",
      " 'ID_railroad_station_avto' 'public_transport_station_min_walk' 'water_km'\n",
      " 'water_1line' 'ID_big_road1' 'big_road1_1line' 'ID_big_road2'\n",
      " 'railroad_km' 'railroad_1line' 'ID_railroad_terminal' 'fitness_km'\n",
      " 'catering_km' 'green_part_500' 'prom_part_500' 'office_sqm_500'\n",
      " 'trc_count_500' 'trc_sqm_500' 'cafe_count_500_na_price'\n",
      " 'cafe_count_500_price_1000' 'cafe_count_500_price_4000'\n",
      " 'cafe_count_500_price_high' 'big_church_count_500' 'mosque_count_500'\n",
      " 'leisure_count_500' 'sport_count_500' 'market_count_500'\n",
      " 'office_sqm_1000' 'trc_sqm_1000' 'cafe_count_1000_price_high'\n",
      " 'mosque_count_1000' 'market_count_1000' 'mosque_count_1500'\n",
      " 'market_count_1500' 'trc_sqm_2000' 'mosque_count_2000'\n",
      " 'mosque_count_3000' 'mosque_count_5000' 'gdp_quart_growth'\n",
      " 'balance_trade_growth' 'net_capital_export' 'deposits_growth'\n",
      " 'mortgage_value' 'day_of_week' 'ratio_kitch_life' 'full_live_diff'\n",
      " 'floor_from_top' 'apartment_name']\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import joblib\n",
    "with open('remain_features.pkl', 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "    print(features)\n",
    "print(len(features))\n",
    "train_X = pd.read_csv('train_X.csv')\n",
    "train_X_selected = train_X[[c for c in train_X.columns if c in features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "APutx21Ji0Ob"
   },
   "outputs": [],
   "source": [
    "# A parameter grid for RF\n",
    "# can add more range\n",
    "# params = {'n_estimators': [40, 80, 120, 160, 200],\n",
    "#                'max_depth': [25, 50, 75, 100, None],\n",
    "#                'min_samples_split': [2, 4, 6],\n",
    "#                'min_samples_leaf': [1, 2, 3],\n",
    "#                'max_features': [\"auto\", \"sqrt\", \"log2\"]}\n",
    "params = {'n_estimators': [120, 160, 200],\n",
    "               'max_depth': [50, 75, 100, None],\n",
    "               'min_samples_split': [2, 4, 6],\n",
    "               'min_samples_leaf': [1, 2, 3],\n",
    "               'max_features': [\"auto\", \"sqrt\"]}\n",
    "mult1 = 1.054\n",
    "mult2 = 1.032\n",
    "# params = {'n_estimators': [20, 40, 60],\n",
    "#                'max_depth': [20],\n",
    "#                'max_features': [\"auto\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "mp6GGHb_i0gD",
    "outputId": "9887b8b8-564a-4c31-e94b-69756007a048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 164.4min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 279.2min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 478.2min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 718.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 726.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "RandomForestRegressor(max_depth=75, max_features='sqrt', min_samples_leaf=3,\n",
      "                      n_estimators=200)\n",
      "\n",
      " Best score:\n",
      "0.3509400679477959\n",
      "\n",
      " Best parameters:\n",
      "{'max_depth': 75, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 177.4min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 298.4min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 504.2min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 743.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 750.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_leaf=3,\n",
      "                      min_samples_split=6, n_estimators=200)\n",
      "\n",
      " Best score:\n",
      "0.3506449297825884\n",
      "\n",
      " Best parameters:\n",
      "{'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "for mult in [mult1, mult2]:\n",
    "    rfr = RandomForestRegressor()\n",
    "    train_y = pd.read_csv('train_y.csv')\n",
    "    train_y['0'] = np.log1p(np.expm1(train_y['0']) * mult)\n",
    "    \n",
    "    rfr_grid = GridSearchCV(rfr, params, cv = 5, n_jobs = -1, verbose=2)\n",
    "\n",
    "    rfr_grid.fit(train_X, train_y)\n",
    "\n",
    "    print('\\n Best estimator:')\n",
    "    print(rfr_grid.best_estimator_)\n",
    "    print('\\n Best score:')\n",
    "    print(rfr_grid.best_score_)\n",
    "    print('\\n Best parameters:')\n",
    "    print(rfr_grid.best_params_)\n",
    "\n",
    "    # save model\n",
    "    if not os.path.exists('cv_models'):\n",
    "        os.makedirs('cv_models')\n",
    "    joblib.dump(rfr_grid, 'cv_models/rfr_grid' + str(mult) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39386,
     "status": "ok",
     "timestamp": 1617699027717,
     "user": {
      "displayName": "Clivian Li",
      "photoUrl": "",
      "userId": "07011166860670723255"
     },
     "user_tz": -480
    },
    "id": "u7-9CVybqP80",
    "outputId": "d104a1c1-04be-4410-9008-b6cb7577bbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 61.2min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 93.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 94.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "RandomForestRegressor(max_depth=100, min_samples_leaf=3, n_estimators=200)\n",
      "\n",
      " Best score:\n",
      "0.28453510876941046\n",
      "\n",
      " Best parameters:\n",
      "{'max_depth': 100, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 62.4min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 94.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 96.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "RandomForestRegressor(max_depth=100, min_samples_leaf=3, n_estimators=200)\n",
      "\n",
      " Best score:\n",
      "0.2851724729146374\n",
      "\n",
      " Best parameters:\n",
      "{'max_depth': 100, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "for mult in [mult1, mult2]:\n",
    "    rfr_selected = RandomForestRegressor()\n",
    "    train_y = pd.read_csv('train_y.csv')\n",
    "    train_y['0'] = np.log1p(np.expm1(train_y['0']) * mult)\n",
    "\n",
    "    rfr_grid_selected = GridSearchCV(rfr_selected, params, cv = 5, n_jobs = -1, verbose=2)\n",
    "\n",
    "    rfr_grid_selected.fit(train_X_selected, train_y)\n",
    "\n",
    "    print('\\n Best estimator:')\n",
    "    print(rfr_grid_selected.best_estimator_)\n",
    "    print('\\n Best score:')\n",
    "    print(rfr_grid_selected.best_score_)\n",
    "    print('\\n Best parameters:')\n",
    "    print(rfr_grid_selected.best_params_)\n",
    "\n",
    "    # save model\n",
    "    if not os.path.exists('cv_models'):\n",
    "        os.makedirs('cv_models')\n",
    "    joblib.dump(rfr_grid_selected, 'cv_models/rfr_grid_selected' + str(mult) + '.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UC-quv0VqspC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "0  15.613451\n",
      "1  15.587476\n",
      "2  16.419622\n",
      "3  16.640102\n",
      "4  14.540157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=100, min_samples_leaf=3, min_samples_split=4,\n",
       "                      n_estimators=160)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_grid = joblib.load('cv_models/rfr_grid.pkl')\n",
    "rfr_grid_selected = joblib.load('cv_models/rfr_grid_selected.pkl')\n",
    "\n",
    "rfr = RandomForestRegressor(**rfr_grid.best_params_)\n",
    "rfr_selected = RandomForestRegressor(**rfr_grid_selected.best_params_)\n",
    "\n",
    "print(train_y.head())\n",
    "\n",
    "train_y['0'] = train_y['0'] * mult\n",
    "\n",
    "rfr.fit(train_X, train_y)\n",
    "rfr_selected.fit(train_X_selected, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 75, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "{'max_depth': 100, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 160}\n"
     ]
    }
   ],
   "source": [
    "print(rfr_grid.best_params_)\n",
    "print(rfr_grid_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-1f8c56df19ac>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-1f8c56df19ac>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    rfr_mult1.fit(train_X, train_y)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "rfr_grid_mult1 = joblib.load('cv_models/rfr_grid' + str(mult1) + '.pkl')\n",
    "rfr_grid_selected_mult1 = joblib.load('cv_models/rfr_grid_selected' + str(mult1) + '.pkl')\n",
    "rfr_grid_mult2 = joblib.load('cv_models/rfr_grid' + str(mult2) + '.pkl')\n",
    "rfr_grid_selected_mult2 = joblib.load('cv_models/rfr_grid_selected' + str(mult2) + '.pkl')\n",
    "grids = [rfr_grid_mult1, rfr_grid_selected_mult1, rfr_grid_mult2, rfr_grid_selected_mult2]\n",
    "for grid in grids:\n",
    "    print(grid.best_params_)\n",
    "    \n",
    "rfr_mult1 = RandomForestRegressor(**rfr_grid_mult1.best_params_)\n",
    "rfr_selected_mult1 = RandomForestRegressor(**rfr_grid_selected_mult2.best_params_)\n",
    "rfr_mult2 = RandomForestRegressor(**rfr_grid_mult2.best_params_)\n",
    "rfr_selected_mult2 = RandomForestRegressor(**rfr_grid_selected_mult2.best_params_)\n",
    "\n",
    "train_y = pd.read_csv('train_y.csv')\n",
    "train_y['0'] = np.log1p(np.expm1(train_y['0']) * mult1\n",
    "rfr_mult1.fit(train_X, train_y)\n",
    "rfr_selected_mult1.fit(train_X_selected, train_y)\n",
    "\n",
    "train_y = pd.read_csv('train_y.csv')\n",
    "train_y['0'] = np.log1p(np.expm1(train_y['0']) * mult2\n",
    "rfr_mult2.fit(train_X, train_y)\n",
    "rfr_selected_mult2.fit(train_X_selected, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.read_csv('test_X_1_clean.csv')\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_selected = test_X[[c for c in train_X.columns if c in features]]\n",
    "models = [rfr_mult1, rfr_selected_mult1, rfr_mult2, rfr_selected_mult2]\n",
    "for i in range(0, len(models)):\n",
    "    model = models[i]\n",
    "    if i = 0 or i = 2:\n",
    "        predict = model.predict(test_X)\n",
    "    elif i = 1 or i = 3:\n",
    "        predict = model.predict(test_X_selected)\n",
    "    print(predict)\n",
    "    predict = np.expm1(predict)\n",
    "    print(predict)\n",
    "    print()\n",
    "    id = np.arange(30474,38136,1)\n",
    "    id.reshape(1,7662)\n",
    "    submission = np.column_stack((id, predict))\n",
    "    df = pd.DataFrame(data=submission, columns=[\"id\", \"price_doc\"])\n",
    "    df['id'] = df['id'].astype('int64')\n",
    "    if not os.path.exists('predict'):\n",
    "        os.makedirs('predict')\n",
    "        df.to_csv('predict/rf_predict_m_' + str(i) + '.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_X.shape[0])\n",
    "test_X_selected = test_X[[c for c in train_X.columns if c in features]]\n",
    "predict = rfr.predict(test_X)\n",
    "predict_selected = rfr_selected.predict(test_X_selected)\n",
    "print(predict)\n",
    "print(predict_selected)\n",
    "predict = np.expm1(predict)\n",
    "predict_selected = np.expm1(predict_selected)\n",
    "print(predict.shape)\n",
    "print(predict_selected.shape)\n",
    "id = np.arange(30474,38136,1)\n",
    "id.reshape(1,7662)\n",
    "submission = np.column_stack((id, predict))\n",
    "submission_selected = np.column_stack((id, predict_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission)\n",
    "print(submission_selected)\n",
    "df = pd.DataFrame(data=submission, columns=[\"id\", \"price_doc\"])\n",
    "df['id'] = df['id'].astype('int64')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pd.DataFrame(data=submission_selected, columns=[\"id\", \"price_doc\"])\n",
    "df_selected['id'] = df_selected['id'].astype('int64')\n",
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('predict'):\n",
    "    os.makedirs('predict')\n",
    "df.to_csv('predict/rf_predict_m.csv', index=False)\n",
    "df_selected.to_csv('predict/rf_selected_predict_m.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM/UxDfa6omLTWZbOdg7Bpq",
   "collapsed_sections": [],
   "name": "GridSearch_RF.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
